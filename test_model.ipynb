{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from pytorch_utils.datasets import ArrayDataset\n",
    "from pytorch_utils.models import FeedforwardNetModel, FixedWidthModel, BottleneckModel\n",
    "import pytorch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'los'\n",
    "\n",
    "data_path = 'data/'\n",
    "features_path = os.path.join(data_path, 'features', str(0))\n",
    "label_path = os.path.join(data_path, 'labels')\n",
    "config_path = os.path.join(data_path, 'config', 'grid', 'baseline')\n",
    "checkpoints_path = os.path.join(data_path, 'checkpoints', 'scratch', outcome)\n",
    "performance_path = os.path.join(data_path, 'performance', 'scratch', outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(checkpoints_path, exist_ok=True)\n",
    "os.makedirs(performance_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = joblib.load(os.path.join(features_path, 'features.pkl'))\n",
    "label_dict = joblib.load(os.path.join(label_path, 'label_dict.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {split: features_dict[split]['features'] for split in features_dict.keys()}\n",
    "outcome_dict = {split : label_dict[split][outcome] for split in label_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(config_path, '{}.yaml'.format(experiment_name)), 'r') as fp:\n",
    "#     config_dict = yaml.load(fp)\n",
    "    \n",
    "# config_dict['num_epochs'] = 3 # For testing\n",
    "\n",
    "## A more complex network\n",
    "# config_dict = {\n",
    "#     'input_dim' : data_dict['train'].shape[1],\n",
    "#     'lr' : 1e-5,\n",
    "#     'num_epochs' : 3,\n",
    "#     'batch_size' : 256,\n",
    "#     'hidden_dim' : 128,\n",
    "#     'num_hidden' : 2,\n",
    "#     'output_dim' : 2,\n",
    "#     'drop_prob' : 0.75,\n",
    "#     'normalize' : True,\n",
    "#     'iters_per_epoch' : 100,\n",
    "#     'gamma' : 0.99,\n",
    "#     'resnet' : True,\n",
    "#     'sparse' : True,\n",
    "#     'sparse_mode' : 'binary'\n",
    "# }\n",
    "# model = FixedWidthModel(config_dict)\n",
    "\n",
    "config_dict = {\n",
    "    'input_dim' : data_dict['train'].shape[1],\n",
    "    'lr' : 1e-2,\n",
    "    'num_epochs' : 10,\n",
    "    'batch_size' : 256,\n",
    "#     'hidden_dim' : 128,\n",
    "    'bottleneck_size' : 64,\n",
    "    'num_hidden' : 2,\n",
    "    'output_dim' : 2,\n",
    "    'drop_prob' : 0.75,\n",
    "    'normalize' : True,\n",
    "    'iters_per_epoch' : 100,\n",
    "    'gamma' : 0.99,\n",
    "    'resnet' : True,\n",
    "    'sparse' : True,\n",
    "    'sparse_mode' : 'binary'\n",
    "}\n",
    "model = BottleneckModel(config_dict)\n",
    "\n",
    "# config_dict = {\n",
    "#     'input_dim' : data_dict['train'].shape[1],\n",
    "#     'lr' : 1e-3,\n",
    "#     'num_epochs' : 3,\n",
    "#     'batch_size' : 256,\n",
    "#     'hidden_dim_list' : [128, 64],\n",
    "#     'output_dim' : 2,\n",
    "#     'drop_prob' : 0.75,\n",
    "#     'normalize' : True,\n",
    "#     'iters_per_epoch' : 100,\n",
    "#     'gamma' : 0.99,\n",
    "#     'resnet' : True,\n",
    "#     'sparse' : True,\n",
    "#     'sparse_mode' : 'binary'\n",
    "# }\n",
    "# model = FeedforwardNetModel(config_dict)\n",
    "for child in model.model.children():\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = model.train(data_dict, outcome_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval = model.predict(data_dict, outcome_dict, phases = ['val', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save weights\n",
    "model.save_weights(os.path.join(checkpoints_path, '{}.chk'.format(experiment_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_training = model.process_result_dict(result)\n",
    "result_df_eval = model.process_result_dict(result_eval[1])\n",
    "\n",
    "print(result_df_training)\n",
    "print(result_df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get performance by group\n",
    "sensitive_variables = ['race_eth', 'gender', 'age']\n",
    "data_dict_by_group = {sensitive_variable: {} for sensitive_variable in sensitive_variables}\n",
    "outcome_dict_by_group = {sensitive_variable: {} for sensitive_variable in sensitive_variables}\n",
    "for sensitive_variable in sensitive_variables:\n",
    "    groups = np.unique(label_dict['train'][sensitive_variable])\n",
    "    for group in groups:\n",
    "        data_dict_by_group[sensitive_variable][group] = {split: \n",
    "                                       data_dict[split][label_dict[split][sensitive_variable] == group]\n",
    "                                       for split in data_dict.keys()\n",
    "                                      }\n",
    "        outcome_dict_by_group[sensitive_variable][group] = {split: \n",
    "                                       outcome_dict[split][label_dict[split][sensitive_variable] == group]\n",
    "                                       for split in data_dict.keys()\n",
    "                                      }\n",
    "result_df_by_group = pd.concat({sensitive_variable: \n",
    "                            pd.concat({\n",
    "                                group: model.process_result_dict(model.predict(data_dict_by_group[sensitive_variable][group],\n",
    "                                                    outcome_dict_by_group[sensitive_variable][group],\n",
    "                                                    phases = ['val', 'test'])[1])\n",
    "                                for group in data_dict_by_group[sensitive_variable].keys()\n",
    "                            })\n",
    "                            for sensitive_variable in data_dict_by_group.keys()\n",
    "                           })\n",
    "result_df_by_group.index = result_df_by_group.index.set_names(['sensitive_variable', 'group', 'index'])\n",
    "result_df_by_group = result_df_by_group.reset_index(level = [0, 1])\n",
    "result_df_by_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df_by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_training.to_csv(os.path.join(performance_path, '{}_training'.format(experiment_name)), index = False)\n",
    "result_df_eval.to_csv(os.path.join(performance_path, '{}_eval'.format(experiment_name)), index = False)\n",
    "result_df_by_group.to_csv(os.path.join(performance_path, '{}_by_group'.format(experiment_name)), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
